syntax = "proto3";
option java_package = "kvas.proto";
option java_outer_classname = "KvasProto";
import "google/protobuf/wrappers.proto";

// Just a key-value pair
message KeyValue {
    string key = 1;
    string value = 2;
}

// Request to get a value by the specified key. The client must supply the request with
// a shard_token value to let the node check if the request is routed correctly.
message KvasGetRequest {
    string key = 1;
    int32 shard_token = 2;
}

// Response to GetValue request.
message KvasGetResponse {
    enum StatusCode {
        // The request was processed by the node and the response is correct.
        OK = 0;
        // The node believes that the client needs to refresh its information about the shards
        // registered in the system.
        REFRESH_SHARDS = 1;
    }
    // The requested value. If the value is missing in the storage, this field shall be empty and
    // KvasGetResponse::hasValue will return false.
    google.protobuf.StringValue value = 1;

    // Status code. The client must check the status code and do what the status code instructs.
    StatusCode code = 2;
}

// Request to put a value by the specified key. The client must supply the request with
// a shard_token value to let the node check if the request is routed correctly.
// In case if there is already such key in the storage, the node must update the value.
message KvasPutRequest {
    // Key the value shall be associated with.
    string key = 1;
    // New value for this key.
    string value = 2;

    // Shard token from the metadata known to the client.
    int32 shard_token = 3;
}

// Response to PutValue request
message KvasPutResponse {
    enum StatusCode {
        // The request was processed by the node and the response is correct.
        OK = 0;
        // The node believes that the client needs to refresh its information about the shards
        // registered in the system.
        REFRESH_SHARDS = 1;
    }
    // Status code. The client must check the status code and do what the status code instructs.
    StatusCode code = 1;
}

// Shard information includes a node IP:port address and an integer token.
// The meaning of token value depends on the chosen sharding function.
//
// For a simple "hash value modulo the number of nodes" it is a remainder of the hash value
// divided by the number of shards.
// For consistent hashing, it is the upper bound of the ring segment served by this node.
// For linear hashing, it is the shard number as calculated by LinearHashing::shardNumber function.
message ShardInfo {
    string node_address = 1;
    int32 shard_token = 2;
}

// Shard must periodically send this request to the master node to register itself in the system, or
// refresh the membership.
// If the node is already registered, it must supply the assigned token.
message RegisterShardRequest {
    string node_address = 1;
    google.protobuf.Int32Value shard_token = 2;
}

// In the response master send the status and the list of the currently available shards.
message RegisterShardResponse {
    enum StatusCode {
        // Shard was registered successfully
        OK = 0;
        // Registration failed because the token conflicts with some other node.
        TOKEN_CONFLICT = 1;
        //
        OTHER = 2;
    }
    int32 shard_token = 1;
    StatusCode code = 2;
    repeated ShardInfo shards = 3;
}

// A client may send this request to the master node to get a list of registered shards.
message GetShardsRequest {
}

// Response to GetShards request.
message GetShardsResponse {
    repeated ShardInfo shards = 1;
}

message MoveDataRequest {
    int32 destination_shard_token = 1;
    repeated ShardInfo shards = 2;
}

// A new replica which joins a replication group sends this request to the current
// leader node.
message ReplicaJoinGroupRequest {
    // IP[:port] address of the replica node.
    string replica_address = 1;
    // The last entry that was committed on this replica. Leave empty if there are no data on this replica.
    // The leader will send AppendLog requests starting from the entry that follows the last committed.
    LogEntry last_committed_entry = 2;
}

message ReplicaJoinGroupResponse {
    int32 replica_token = 1;
}

// A log entry is a key-value pair with the ordinal number that is used for ordering the events.
message LogEntry {
    // The key and the value
    KeyValue kv = 1;
    // Ordinal number of this log entry.
    int32 ordinal_number = 2;
}

// The leader replica sends these requests to the followers when key-values are updated.
// Key-value pairs in "entries" field must be in the order of their committing on the leader.
// The follower replica must write the log entries into its own log and reply when the write is
// committed. After that the follower can apply the log to its own storage.
message ReplicaAppendLogRequest {
    repeated LogEntry entries = 1;
}

message ReplicaAppendLogResponse {
    LogEntry last_committed_entry = 1;
}

// The client may request addresses of the replica group instances from the leader to balance the
// load across all replicas.
message ReplicaGetGroupRequest {
}

message ReplicaGetGroupResponse {
    // The list of HOST[:PORT] addresses of the replica group instances.
    // HOST is either an IP address or a node name; optional PORT number follows
    // the HOST part and is separated with a colon.
    repeated ShardInfo replicas = 1;
}

// GRPC server interface.
service Kvas {
    rpc GetValue(KvasGetRequest) returns (KvasGetResponse) {}
    rpc PutValue(KvasPutRequest) returns (KvasPutResponse) {}

    rpc RegisterShard(RegisterShardRequest) returns (RegisterShardResponse) {}
    rpc GetShards(GetShardsRequest) returns (GetShardsResponse) {}

    rpc MoveData(MoveDataRequest) returns (stream KeyValue){}

    rpc ReplicaJoinGroup(ReplicaJoinGroupRequest) returns (ReplicaJoinGroupResponse) {}
    rpc ReplicaAppendLog(ReplicaAppendLogRequest) returns (ReplicaAppendLogResponse) {}
    rpc ReplicaGetGroup(ReplicaGetGroupRequest) returns (ReplicaGetGroupResponse) {}
}
